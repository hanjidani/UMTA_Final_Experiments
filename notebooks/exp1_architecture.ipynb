{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UMTA Experiment 1: Architecture Search (Kaggle Notebook - Parallel Execution)\n",
        "\n",
        "This notebook runs **Experiment 1** with parallel execution support.\n",
        "\n",
        "## Parallel Execution Strategy\n",
        "- **10 separate Kaggle notebooks** (one per pair)\n",
        "- Each notebook runs **1 pair** across **4 architectures**\n",
        "- Set `PAIR_INDEX` in Cell 3 to select which pair to run\n",
        "\n",
        "**Repo:** https://github.com/hanjidani/UMTA_Final_Experiments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Install Dependencies\n",
        "# Install required libraries for CLIP and training\n",
        "\n",
        "!pip install -q ftfy regex tqdm\n",
        "!pip install -q git+https://github.com/openai/CLIP.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Clone Repository\n",
        "\n",
        "import os\n",
        "\n",
        "# Remove existing repo to ensure we get the latest code\n",
        "if os.path.exists(\"UMTA_Final_Experiments\"):\n",
        "    !rm -rf UMTA_Final_Experiments\n",
        "\n",
        "# Clone the repository\n",
        "!git clone https://github.com/hanjidani/UMTA_Final_Experiments.git\n",
        "\n",
        "# Move into the directory\n",
        "%cd UMTA_Final_Experiments\n",
        "\n",
        "print(\"âœ… Repository cloned and ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Unify Kaggle Dataset Structure\n",
        "# This cell handles Kaggle's split dataset folders (train.X1, train.X2, etc.)\n",
        "# and merges them into a single unified structure using symbolic links\n",
        "\n",
        "import os\n",
        "import yaml\n",
        "\n",
        "# Define paths\n",
        "input_root = \"/kaggle/input/imagenet100\"\n",
        "unified_root = \"/tmp/imagenet100\"  # Unified dataset location\n",
        "\n",
        "print(f\"ðŸ› ï¸ Fixing Kaggle dataset structure from {input_root}...\")\n",
        "\n",
        "# Create destination folders\n",
        "os.makedirs(f\"{unified_root}/train\", exist_ok=True)\n",
        "os.makedirs(f\"{unified_root}/val\", exist_ok=True)\n",
        "\n",
        "# Merge 'train.X*' folders into a single 'train' folder using symlinks\n",
        "# This makes Python think it's one big folder without actually copying files\n",
        "!cp -rs {input_root}/train.X*/* {unified_root}/train/ 2>/dev/null || echo \"No train.X* folders found, checking for single train folder...\"\n",
        "!cp -rs {input_root}/val.X*/* {unified_root}/val/ 2>/dev/null || echo \"No val.X* folders found, checking for single val folder...\"\n",
        "\n",
        "# Fallback: If no split folders, try direct copy/symlink\n",
        "if not os.listdir(f\"{unified_root}/train\"):\n",
        "    !cp -rs {input_root}/train/* {unified_root}/train/ 2>/dev/null || true\n",
        "if not os.listdir(f\"{unified_root}/val\"):\n",
        "    !cp -rs {input_root}/val/* {unified_root}/val/ 2>/dev/null || true\n",
        "\n",
        "print(\"âœ… Dataset unified successfully!\")\n",
        "\n",
        "# Update config file to point to unified location\n",
        "config_path = 'exp1_architecture/config.yaml'\n",
        "\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Point config to the new unified location\n",
        "if 'data' not in config:\n",
        "    config['data'] = {}\n",
        "config['data']['path'] = unified_root\n",
        "\n",
        "with open(config_path, 'w') as f:\n",
        "    yaml.dump(config, f, default_flow_style=False)\n",
        "\n",
        "print(f\"âœ… Config updated to read from: {unified_root}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Select Pair Index (USER INPUT)\n",
        "# ==========================================\n",
        "#        KAGGLE PARALLEL CONFIGURATION\n",
        "# ==========================================\n",
        "# Set this index from 0 to 9 to run a specific pair.\n",
        "# Open 10 separate Kaggle tabs and assign a unique index to each.\n",
        "#\n",
        "# Pairs:\n",
        "# 0: Fish -> Shark       (Easy)\n",
        "# 1: Finch -> Bunting    (Easy)\n",
        "# 2: Plant -> Frog       (Med-Easy)\n",
        "# 3: Dog -> Cat          (Med-Easy)\n",
        "# 4: Truck -> Car        (Medium)\n",
        "# 5: Snake -> Lizard     (Medium)\n",
        "# 6: Bird -> Object      (Med-Hard)\n",
        "# 7: Bird -> Artifact    (Med-Hard)\n",
        "# 8: Fish -> Paper       (Hard)\n",
        "# 9: Fish -> Traffic Light (Hard)\n",
        "# ==========================================\n",
        "\n",
        "PAIR_INDEX = 0  # <--- CHANGE THIS VALUE (0-9)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Run Experiment\n",
        "# Execute the training script with the selected pair index\n",
        "# The script handles architecture creation, training, and saving results.\n",
        "\n",
        "print(f\"Starting Experiment 1 for Pair Index: {PAIR_INDEX}\")\n",
        "!python exp1_architecture/run.py --pair_index {PAIR_INDEX}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Download Results\n",
        "# Create a download link for the results CSV\n",
        "\n",
        "from IPython.display import FileLink, display\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Find the latest results directory\n",
        "results_base = Path(\"exp1_architecture/results\")\n",
        "if results_base.exists():\n",
        "    # Get the most recent timestamped directory\n",
        "    result_dirs = sorted([d for d in results_base.iterdir() if d.is_dir()], reverse=True)\n",
        "    if result_dirs:\n",
        "        latest_dir = result_dirs[0]\n",
        "        result_file = latest_dir / \"results.csv\"\n",
        "        \n",
        "        if result_file.exists():\n",
        "            print(f\"âœ… Experiment Complete!\")\n",
        "            print(f\"Results saved in: {latest_dir}\")\n",
        "            print(f\"\\nClick below to download results for Pair {PAIR_INDEX}:\")\n",
        "            display(FileLink(str(result_file)))\n",
        "        else:\n",
        "            print(f\"âš ï¸ Results directory found but results.csv not found in {latest_dir}\")\n",
        "    else:\n",
        "        print(\"âš ï¸ No results directories found\")\n",
        "else:\n",
        "    print(\"âš ï¸ Results directory not found. Check the training logs above for errors.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
