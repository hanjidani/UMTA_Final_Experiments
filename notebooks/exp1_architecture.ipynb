{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UMTA Experiment 1: Architecture Search (Kaggle Notebook - Multi-GPU)\n",
        "\n",
        "This notebook runs **Experiment 1** with **multi-GPU parallel execution**.\n",
        "\n",
        "## Multi-GPU Execution Strategy\n",
        "- **Automatically detects and uses all available GPUs** (e.g., 2x T4)\n",
        "- **Splits architectures across GPUs** for parallel training\n",
        "- **Example:** With 2 GPUs and 4 architectures:\n",
        "  - GPU 0: SimpleCNN, ResUNet\n",
        "  - GPU 1: UNet, AttentionUNet\n",
        "- **~2x faster** than sequential execution\n",
        "\n",
        "**Repo:** https://github.com/hanjidani/UMTA_Final_Experiments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Install Dependencies\n",
        "# Install required libraries for CLIP and training\n",
        "\n",
        "!pip install -q ftfy regex tqdm\n",
        "!pip install -q git+https://github.com/openai/CLIP.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Clone Repository\n",
        "\n",
        "import os\n",
        "\n",
        "# Remove existing repo to ensure we get the latest code\n",
        "if os.path.exists(\"UMTA_Final_Experiments\"):\n",
        "    !rm -rf UMTA_Final_Experiments\n",
        "\n",
        "# Clone the repository\n",
        "!git clone https://github.com/hanjidani/UMTA_Final_Experiments.git\n",
        "\n",
        "# Move into the directory\n",
        "%cd UMTA_Final_Experiments\n",
        "\n",
        "print(\"‚úÖ Repository cloned and ready\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Unify Kaggle Dataset Structure\n",
        "# This cell handles Kaggle's split dataset folders (train.X1, train.X2, etc.)\n",
        "# and merges them into a single unified structure using symbolic links\n",
        "\n",
        "import os\n",
        "import yaml\n",
        "\n",
        "# Define paths\n",
        "input_root = \"/kaggle/input/imagenet100\"\n",
        "unified_root = \"/tmp/imagenet100\"  # Unified dataset location\n",
        "\n",
        "print(f\"üõ†Ô∏è Fixing Kaggle dataset structure from {input_root}...\")\n",
        "\n",
        "# Create destination folders\n",
        "os.makedirs(f\"{unified_root}/train\", exist_ok=True)\n",
        "os.makedirs(f\"{unified_root}/val\", exist_ok=True)\n",
        "\n",
        "# Merge 'train.X*' folders into a single 'train' folder using symlinks\n",
        "# This makes Python think it's one big folder without actually copying files\n",
        "!cp -rs {input_root}/train.X*/* {unified_root}/train/ 2>/dev/null || echo \"No train.X* folders found, checking for single train folder...\"\n",
        "!cp -rs {input_root}/val.X*/* {unified_root}/val/ 2>/dev/null || echo \"No val.X* folders found, checking for single val folder...\"\n",
        "\n",
        "# Fallback: If no split folders, try direct copy/symlink\n",
        "if not os.listdir(f\"{unified_root}/train\"):\n",
        "    !cp -rs {input_root}/train/* {unified_root}/train/ 2>/dev/null || true\n",
        "if not os.listdir(f\"{unified_root}/val\"):\n",
        "    !cp -rs {input_root}/val/* {unified_root}/val/ 2>/dev/null || true\n",
        "\n",
        "print(\"‚úÖ Dataset unified successfully!\")\n",
        "\n",
        "# Update config file to point to unified location\n",
        "config_path = 'exp1_architecture/config.yaml'\n",
        "\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Point config to the new unified location\n",
        "if 'data' not in config:\n",
        "    config['data'] = {}\n",
        "config['data']['path'] = unified_root\n",
        "\n",
        "with open(config_path, 'w') as f:\n",
        "    yaml.dump(config, f, default_flow_style=False)\n",
        "\n",
        "print(f\"‚úÖ Config updated to read from: {unified_root}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update config file to point to unified location\n",
        "config_path = 'exp1_architecture/config.yaml'\n",
        "\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Point config to the new unified location\n",
        "if 'data' not in config:\n",
        "    config['data'] = {}\n",
        "config['data']['path'] = unified_root\n",
        "\n",
        "with open(config_path, 'w') as f:\n",
        "    yaml.dump(config, f, default_flow_style=False)\n",
        "\n",
        "print(f\"‚úÖ Config updated to read from: {unified_root}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Select Pair Index (Optional) + Check GPU Availability\n",
        "# ==========================================\n",
        "#        PAIR SELECTION (OPTIONAL)\n",
        "# ==========================================\n",
        "# Set this to None to run ALL pairs from config\n",
        "# Or set to 0-9 to run a specific pair across all architectures\n",
        "#\n",
        "# Pairs:\n",
        "# 0: Fish -> Shark       (Easy)\n",
        "# 1: Finch -> Bunting    (Easy)\n",
        "# 2: Plant -> Frog       (Med-Easy)\n",
        "# 3: Dog -> Cat          (Med-Easy)\n",
        "# 4: Truck -> Car        (Medium)\n",
        "# 5: Snake -> Lizard     (Medium)\n",
        "# 6: Bird -> Object      (Med-Hard)\n",
        "# 7: Bird -> Artifact    (Med-Hard)\n",
        "# 8: Fish -> Paper       (Hard)\n",
        "# 9: Fish -> Traffic Light (Hard)\n",
        "# ==========================================\n",
        "\n",
        "PAIR_INDEX = None  # <--- Set to None for all pairs, or 0-9 for specific pair\n",
        "\n",
        "# Check GPU availability\n",
        "import torch\n",
        "\n",
        "num_gpus = torch.cuda.device_count() if torch.cuda.is_available() else 0\n",
        "\n",
        "print(f\"üîç GPU Detection:\")\n",
        "print(f\"   Available GPUs: {num_gpus}\")\n",
        "\n",
        "if num_gpus > 0:\n",
        "    for i in range(num_gpus):\n",
        "        gpu_name = torch.cuda.get_device_name(i)\n",
        "        gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1e9\n",
        "        print(f\"   GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
        "    \n",
        "    if num_gpus >= 2:\n",
        "        print(f\"\\n‚úÖ Multi-GPU mode enabled: {num_gpus} GPUs will train architectures in parallel\")\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è  Only {num_gpus} GPU available. Will use single-GPU mode.\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  No GPUs detected. Will use CPU (very slow).\")\n",
        "\n",
        "if PAIR_INDEX is not None:\n",
        "    print(f\"\\nüìå Running Pair Index: {PAIR_INDEX}\")\n",
        "else:\n",
        "    print(f\"\\nüìå Running: All pairs from config\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Run Experiment (Multi-GPU Mode)\n",
        "# Execute the training script with multi-GPU parallel execution\n",
        "# The script automatically splits architectures across available GPUs\n",
        "# If PAIR_INDEX is set, runs that specific pair; otherwise runs all pairs\n",
        "\n",
        "if PAIR_INDEX is not None:\n",
        "    print(f\"üöÄ Starting Experiment 1: Pair {PAIR_INDEX} with Multi-GPU Parallel Execution...\")\n",
        "    print(\"=\" * 60)\n",
        "    !python exp1_architecture/run.py --multi_gpu --pair_index {PAIR_INDEX}\n",
        "else:\n",
        "    print(\"üöÄ Starting Experiment 1: All Pairs with Multi-GPU Parallel Execution...\")\n",
        "    print(\"=\" * 60)\n",
        "    !python exp1_architecture/run.py --multi_gpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Download Results\n",
        "# Create download links for the results CSV and summary\n",
        "\n",
        "from IPython.display import FileLink, display\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Find the latest results directory (multi-GPU results have \"multi_gpu_\" prefix)\n",
        "results_base = Path(\"exp1_architecture/results\")\n",
        "if results_base.exists():\n",
        "    # Get the most recent timestamped directory (prefer multi_gpu_ directories)\n",
        "    result_dirs = sorted([d for d in results_base.iterdir() if d.is_dir()], reverse=True)\n",
        "    \n",
        "    # Prefer multi_gpu_ directories if available\n",
        "    multi_gpu_dirs = [d for d in result_dirs if \"multi_gpu\" in d.name]\n",
        "    if multi_gpu_dirs:\n",
        "        latest_dir = multi_gpu_dirs[0]\n",
        "    elif result_dirs:\n",
        "        latest_dir = result_dirs[0]\n",
        "    else:\n",
        "        latest_dir = None\n",
        "    \n",
        "    if latest_dir:\n",
        "        result_file = latest_dir / \"results.csv\"\n",
        "        summary_file = latest_dir / \"summary.csv\"\n",
        "        best_arch_file = latest_dir / \"best_architecture.json\"\n",
        "        \n",
        "        if result_file.exists():\n",
        "            print(f\"‚úÖ Experiment Complete!\")\n",
        "            print(f\"Results saved in: {latest_dir}\")\n",
        "            print(f\"\\nüìä Download Results:\")\n",
        "            display(FileLink(str(result_file)))\n",
        "            \n",
        "            if summary_file.exists():\n",
        "                print(f\"\\nüìà Download Summary:\")\n",
        "                display(FileLink(str(summary_file)))\n",
        "            \n",
        "            if best_arch_file.exists():\n",
        "                print(f\"\\nüèÜ Download Best Architecture:\")\n",
        "                display(FileLink(str(best_arch_file)))\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Results directory found but results.csv not found in {latest_dir}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No results directories found\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Results directory not found. Check the training logs above for errors.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
